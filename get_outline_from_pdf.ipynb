{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\Users\\Yi-Ming\\Documents\\Python\\handson_ml\\books\\Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow (Third Edition).pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "def bookmark_dict(bookmark_list, indent=0):\n",
    "    result = {}\n",
    "    for item in bookmark_list:\n",
    "        if isinstance(item, list):\n",
    "            # recursive call\n",
    "            result.update(bookmark_dict(item, indent+1))\n",
    "        else:\n",
    "            result[reader.get_destination_page_number(item)] = '#'*(indent+2) + ' ' + item.title\n",
    "    return result\n",
    "\n",
    "reader = PyPDF2.PdfReader(filename)\n",
    "\n",
    "result = bookmark_dict(reader.outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Preface\n",
      "### The Machine Learning Tsunami\n",
      "### Machine Learning in Your Projects\n",
      "### Objective and Approach\n",
      "### Code Examples\n",
      "### Prerequisites\n",
      "### Roadmap\n",
      "### Changes Between the First and the Second Edition\n",
      "### Changes Between the Second and the Third Edition\n",
      "### Other Resources\n",
      "### Conventions Used in This Book\n",
      "### O’Reilly Online Learning\n",
      "### How to Contact Us\n",
      "### Acknowledgments\n",
      "## I. The Fundamentals of Machine Learning\n",
      "## 1. The Machine Learning Landscape\n",
      "### What Is Machine Learning?\n",
      "### Why Use Machine Learning?\n",
      "### Examples of Applications\n",
      "### Types of Machine Learning Systems\n",
      "#### Training Supervision\n",
      "#### Batch Versus Online Learning\n",
      "#### Instance-Based Versus Model-Based Learning\n",
      "### Main Challenges of Machine Learning\n",
      "#### Insufficient Quantity of Training Data\n",
      "#### Nonrepresentative Training Data\n",
      "#### Poor-Quality Data\n",
      "#### Irrelevant Features\n",
      "#### Overfitting the Training Data\n",
      "#### Underfitting the Training Data\n",
      "#### Stepping Back\n",
      "### Testing and Validating\n",
      "#### Hyperparameter Tuning and Model Selection\n",
      "#### Data Mismatch\n",
      "### Exercises\n",
      "## 2. End-to-End Machine Learning Project\n",
      "### Working with Real Data\n",
      "### Look at the Big Picture\n",
      "#### Frame the Problem\n",
      "#### Select a Performance Measure\n",
      "#### Check the Assumptions\n",
      "### Get the Data\n",
      "#### Running the Code Examples Using Google Colab\n",
      "#### Saving Your Code Changes and Your Data\n",
      "#### Book Code Versus Notebook Code\n",
      "#### Download the Data\n",
      "#### Take a Quick Look at the Data Structure\n",
      "#### Create a Test Set\n",
      "### Explore and Visualize the Data to Gain Insights\n",
      "#### Visualizing Geographical Data\n",
      "#### Look for Correlations\n",
      "#### Experiment with Attribute Combinations\n",
      "### Prepare the Data for Machine Learning Algorithms\n",
      "#### Clean the Data\n",
      "#### Handling Text and Categorical Attributes\n",
      "#### Feature Scaling and Transformation\n",
      "#### Custom Transformers\n",
      "#### Transformation Pipelines\n",
      "### Select and Train a Model\n",
      "#### Train and Evaluate on the Training Set\n",
      "#### Better Evaluation Using Cross-Validation\n",
      "### Fine-Tune Your Model\n",
      "#### Grid Search\n",
      "#### Randomized Search\n",
      "#### Ensemble Methods\n",
      "#### Analyzing the Best Models and Their Errors\n",
      "#### Evaluate Your System on the Test Set\n",
      "### Launch, Monitor, and Maintain Your System\n",
      "### Try It Out!\n",
      "### Exercises\n",
      "## 3. Classification\n",
      "### MNIST\n",
      "### Training a Binary Classifier\n",
      "### Performance Measures\n",
      "#### Measuring Accuracy Using Cross-Validation\n",
      "#### Confusion Matrices\n",
      "#### Precision and Recall\n",
      "#### The Precision/Recall Trade-off\n",
      "#### The ROC Curve\n",
      "### Multiclass Classification\n",
      "### Error Analysis\n",
      "### Multilabel Classification\n",
      "### Multioutput Classification\n",
      "### Exercises\n",
      "## 4. Training Models\n",
      "### Linear Regression\n",
      "#### The Normal Equation\n",
      "#### Computational Complexity\n",
      "### Gradient Descent\n",
      "#### Batch Gradient Descent\n",
      "#### Stochastic Gradient Descent\n",
      "#### Mini-Batch Gradient Descent\n",
      "### Polynomial Regression\n",
      "### Learning Curves\n",
      "### Regularized Linear Models\n",
      "#### Ridge Regression\n",
      "#### Lasso Regression\n",
      "#### Elastic Net Regression\n",
      "#### Early Stopping\n",
      "### Logistic Regression\n",
      "#### Estimating Probabilities\n",
      "#### Training and Cost Function\n",
      "#### Decision Boundaries\n",
      "#### Softmax Regression\n",
      "### Exercises\n",
      "## 5. Support Vector Machines\n",
      "### Linear SVM Classification\n",
      "#### Soft Margin Classification\n",
      "### Nonlinear SVM Classification\n",
      "#### Polynomial Kernel\n",
      "#### Similarity Features\n",
      "#### Gaussian RBF Kernel\n",
      "#### SVM Classes and Computational Complexity\n",
      "### SVM Regression\n",
      "### Under the Hood of Linear SVM Classifiers\n",
      "### The Dual Problem\n",
      "#### Kernelized SVMs\n",
      "### Exercises\n",
      "## 6. Decision Trees\n",
      "### Training and Visualizing a Decision Tree\n",
      "### Making Predictions\n",
      "### Estimating Class Probabilities\n",
      "### The CART Training Algorithm\n",
      "### Computational Complexity\n",
      "### Gini Impurity or Entropy?\n",
      "### Regularization Hyperparameters\n",
      "### Regression\n",
      "### Sensitivity to Axis Orientation\n",
      "### Decision Trees Have a High Variance\n",
      "### Exercises\n",
      "## 7. Ensemble Learning and Random Forests\n",
      "### Voting Classifiers\n",
      "### Bagging and Pasting\n",
      "#### Bagging and Pasting in Scikit-Learn\n",
      "#### Out-of-Bag Evaluation\n",
      "#### Random Patches and Random Subspaces\n",
      "### Random Forests\n",
      "#### Extra-Trees\n",
      "#### Feature Importance\n",
      "### Boosting\n",
      "#### AdaBoost\n",
      "#### Gradient Boosting\n",
      "#### Histogram-Based Gradient Boosting\n",
      "### Stacking\n",
      "### Exercises\n",
      "## 8. Dimensionality Reduction\n",
      "### The Curse of Dimensionality\n",
      "### Main Approaches for Dimensionality Reduction\n",
      "#### Projection\n",
      "#### Manifold Learning\n",
      "### PCA\n",
      "#### Preserving the Variance\n",
      "#### Principal Components\n",
      "#### Projecting Down to d Dimensions\n",
      "#### Using Scikit-Learn\n",
      "#### Explained Variance Ratio\n",
      "#### Choosing the Right Number of Dimensions\n",
      "#### PCA for Compression\n",
      "#### Randomized PCA\n",
      "#### Incremental PCA\n",
      "### Random Projection\n",
      "### LLE\n",
      "### Other Dimensionality Reduction Techniques\n",
      "### Exercises\n",
      "## 9. Unsupervised Learning Techniques\n",
      "### Clustering Algorithms: k-means and DBSCAN\n",
      "#### k-means\n",
      "#### Limits of k-means\n",
      "#### Using Clustering for Image Segmentation\n",
      "#### Using Clustering for Semi-Supervised Learning\n",
      "#### DBSCAN\n",
      "#### Other Clustering Algorithms\n",
      "### Gaussian Mixtures\n",
      "#### Using Gaussian Mixtures for Anomaly Detection\n",
      "#### Selecting the Number of Clusters\n",
      "#### Bayesian Gaussian Mixture Models\n",
      "#### Other Algorithms for Anomaly and Novelty Detection\n",
      "### Exercises\n",
      "## II. Neural Networks and Deep Learning\n",
      "## 10. Introduction to Artificial Neural Networks with Keras\n",
      "### From Biological to Artificial Neurons\n",
      "#### Biological Neurons\n",
      "#### Logical Computations with Neurons\n",
      "#### The Perceptron\n",
      "#### The Multilayer Perceptron and Backpropagation\n",
      "#### Regression MLPs\n",
      "#### Classification MLPs\n",
      "### Implementing MLPs with Keras\n",
      "#### Building an Image Classifier Using the Sequential API\n",
      "#### Building a Regression MLP Using the Sequential API\n",
      "#### Building Complex Models Using the Functional API\n",
      "#### Using the Subclassing API to Build Dynamic Models\n",
      "#### Saving and Restoring a Model\n",
      "#### Using Callbacks\n",
      "#### Using TensorBoard for Visualization\n",
      "### Fine-Tuning Neural Network Hyperparameters\n",
      "#### Number of Hidden Layers\n",
      "#### Number of Neurons per Hidden Layer\n",
      "#### Learning Rate, Batch Size, and Other Hyperparameters\n",
      "### Exercises\n",
      "## 11. Training Deep Neural Networks\n",
      "### The Vanishing/Exploding Gradients Problems\n",
      "#### Glorot and He Initialization\n",
      "#### Better Activation Functions\n",
      "#### Batch Normalization\n",
      "#### Gradient Clipping\n",
      "### Reusing Pretrained Layers\n",
      "#### Transfer Learning with Keras\n",
      "#### Unsupervised Pretraining\n",
      "#### Pretraining on an Auxiliary Task\n",
      "### Faster Optimizers\n",
      "#### Momentum\n",
      "#### Nesterov Accelerated Gradient\n",
      "#### AdaGrad\n",
      "#### RMSProp\n",
      "#### Adam\n",
      "#### AdaMax\n",
      "#### Nadam\n",
      "#### AdamW\n",
      "### Learning Rate Scheduling\n",
      "### Avoiding Overfitting Through Regularization\n",
      "#### ℓ1 and ℓ2 Regularization\n",
      "#### Dropout\n",
      "#### Monte Carlo (MC) Dropout\n",
      "#### Max-Norm Regularization\n",
      "### Summary and Practical Guidelines\n",
      "### Exercises\n",
      "## 12. Custom Models and Training with TensorFlow\n",
      "### A Quick Tour of TensorFlow\n",
      "### Using TensorFlow like NumPy\n",
      "#### Tensors and Operations\n",
      "#### Tensors and NumPy\n",
      "#### Type Conversions\n",
      "#### Variables\n",
      "#### Other Data Structures\n",
      "### Customizing Models and Training Algorithms\n",
      "#### Custom Loss Functions\n",
      "#### Saving and Loading Models That Contain Custom Components\n",
      "#### Custom Activation Functions, Initializers, Regularizers, and Constraints\n",
      "#### Custom Metrics\n",
      "#### Custom Layers\n",
      "#### Custom Models\n",
      "#### Losses and Metrics Based on Model Internals\n",
      "#### Computing Gradients Using Autodiff\n",
      "#### Custom Training Loops\n",
      "### TensorFlow Functions and Graphs\n",
      "#### AutoGraph and Tracing\n",
      "#### TF Function Rules\n",
      "### Exercises\n",
      "## 13. Loading and Preprocessing Data with TensorFlow\n",
      "### The tf.data API\n",
      "#### Chaining Transformations\n",
      "#### Shuffling the Data\n",
      "#### Interleaving Lines from Multiple Files\n",
      "#### Preprocessing the Data\n",
      "#### Putting Everything Together\n",
      "#### Prefetching\n",
      "#### Using the Dataset with Keras\n",
      "### The TFRecord Format\n",
      "#### Compressed TFRecord Files\n",
      "#### A Brief Introduction to Protocol Buffers\n",
      "#### TensorFlow Protobufs\n",
      "#### Loading and Parsing Examples\n",
      "#### Handling Lists of Lists Using the SequenceExample Protobuf\n",
      "### Keras Preprocessing Layers\n",
      "#### The Normalization Layer\n",
      "#### The Discretization Layer\n",
      "#### The CategoryEncoding Layer\n",
      "#### The StringLookup Layer\n",
      "#### The Hashing Layer\n",
      "#### Encoding Categorical Features Using Embeddings\n",
      "#### Text Preprocessing\n",
      "#### Using Pretrained Language Model Components\n",
      "#### Image Preprocessing Layers\n",
      "### The TensorFlow Datasets Project\n",
      "### Exercises\n",
      "## 14. Deep Computer Vision Using Convolutional Neural Networks\n",
      "### The Architecture of the Visual Cortex\n",
      "### Convolutional Layers\n",
      "#### Filters\n",
      "#### Stacking Multiple Feature Maps\n",
      "#### Implementing Convolutional Layers with Keras\n",
      "#### Memory Requirements\n",
      "### Pooling Layers\n",
      "### Implementing Pooling Layers with Keras\n",
      "### CNN Architectures\n",
      "#### LeNet-5\n",
      "#### AlexNet\n",
      "#### GoogLeNet\n",
      "#### VGGNet\n",
      "#### ResNet\n",
      "#### Xception\n",
      "#### SENet\n",
      "#### Other Noteworthy Architectures\n",
      "#### Choosing the Right CNN Architecture\n",
      "### Implementing a ResNet-34 CNN Using Keras\n",
      "### Using Pretrained Models from Keras\n",
      "### Pretrained Models for Transfer Learning\n",
      "### Classification and Localization\n",
      "### Object Detection\n",
      "#### Fully Convolutional Networks\n",
      "#### You Only Look Once\n",
      "### Object Tracking\n",
      "### Semantic Segmentation\n",
      "### Exercises\n",
      "## 15. Processing Sequences Using RNNs and CNNs\n",
      "### Recurrent Neurons and Layers\n",
      "#### Memory Cells\n",
      "#### Input and Output Sequences\n",
      "### Training RNNs\n",
      "### Forecasting a Time Series\n",
      "#### The ARMA Model Family\n",
      "#### Preparing the Data for Machine Learning Models\n",
      "#### Forecasting Using a Linear Model\n",
      "#### Forecasting Using a Simple RNN\n",
      "#### Forecasting Using a Deep RNN\n",
      "#### Forecasting Multivariate Time Series\n",
      "#### Forecasting Several Time Steps Ahead\n",
      "#### Forecasting Using a Sequence-to-Sequence Model\n",
      "### Handling Long Sequences\n",
      "#### Fighting the Unstable Gradients Problem\n",
      "#### Tackling the Short-Term Memory Problem\n",
      "### Exercises\n",
      "## 16. Natural Language Processing with RNNs and Attention\n",
      "### Generating Shakespearean Text Using a Character RNN\n",
      "#### Creating the Training Dataset\n",
      "#### Building and Training the Char-RNN Model\n",
      "#### Generating Fake Shakespearean Text\n",
      "#### Stateful RNN\n",
      "### Sentiment Analysis\n",
      "#### Masking\n",
      "#### Reusing Pretrained Embeddings and Language Models\n",
      "### An Encoder–Decoder Network for Neural Machine Translation\n",
      "#### Bidirectional RNNs\n",
      "#### Beam Search\n",
      "### Attention Mechanisms\n",
      "#### Attention Is All You Need: The Original Transformer Architecture\n",
      "### An Avalanche of Transformer Models\n",
      "### Vision Transformers\n",
      "### Hugging Face’s Transformers Library\n",
      "### Exercises\n",
      "## 17. Autoencoders, GANs, and Diffusion Models\n",
      "### Efficient Data Representations\n",
      "### Performing PCA with an Undercomplete Linear Autoencoder\n",
      "### Stacked Autoencoders\n",
      "#### Implementing a Stacked Autoencoder Using Keras\n",
      "#### Visualizing the Reconstructions\n",
      "#### Visualizing the Fashion MNIST Dataset\n",
      "#### Unsupervised Pretraining Using Stacked Autoencoders\n",
      "#### Tying Weights\n",
      "#### Training One Autoencoder at a Time\n",
      "### Convolutional Autoencoders\n",
      "### Denoising Autoencoders\n",
      "### Sparse Autoencoders\n",
      "### Variational Autoencoders\n",
      "### Generating Fashion MNIST Images\n",
      "### Generative Adversarial Networks\n",
      "#### The Difficulties of Training GANs\n",
      "#### Deep Convolutional GANs\n",
      "#### Progressive Growing of GANs\n",
      "#### StyleGANs\n",
      "### Diffusion Models\n",
      "### Exercises\n",
      "## 18. Reinforcement Learning\n",
      "### Learning to Optimize Rewards\n",
      "### Policy Search\n",
      "### Introduction to OpenAI Gym\n",
      "### Neural Network Policies\n",
      "### Evaluating Actions: The Credit Assignment Problem\n",
      "### Policy Gradients\n",
      "### Markov Decision Processes\n",
      "### Temporal Difference Learning\n",
      "### Q-Learning\n",
      "#### Exploration Policies\n",
      "#### Approximate Q-Learning and Deep Q-Learning\n",
      "### Implementing Deep Q-Learning\n",
      "### Deep Q-Learning Variants\n",
      "#### Fixed Q-value Targets\n",
      "#### Double DQN\n",
      "#### Prioritized Experience Replay\n",
      "#### Dueling DQN\n",
      "### Overview of Some Popular RL Algorithms\n",
      "### Exercises\n",
      "## 19. Training and Deploying TensorFlow Models at Scale\n",
      "### Serving a TensorFlow Model\n",
      "#### Using TensorFlow Serving\n",
      "#### Creating a Prediction Service on Vertex AI\n",
      "#### Running Batch Prediction Jobs on Vertex AI\n",
      "### Deploying a Model to a Mobile or Embedded Device\n",
      "### Running a Model in a Web Page\n",
      "### Using GPUs to Speed Up Computations\n",
      "#### Getting Your Own GPU\n",
      "#### Managing the GPU RAM\n",
      "#### Placing Operations and Variables on Devices\n",
      "#### Parallel Execution Across Multiple Devices\n",
      "### Training Models Across Multiple Devices\n",
      "#### Model Parallelism\n",
      "#### Data Parallelism\n",
      "#### Training at Scale Using the Distribution Strategies API\n",
      "#### Training a Model on a TensorFlow Cluster\n",
      "#### Running Large Training Jobs on Vertex AI\n",
      "#### Hyperparameter Tuning on Vertex AI\n",
      "### Exercises\n",
      "### Thank You!\n",
      "## A. Machine Learning Project Checklist\n",
      "### Frame the Problem and Look at the Big Picture\n",
      "### Get the Data\n",
      "### Explore the Data\n",
      "### Prepare the Data\n",
      "### Shortlist Promising Models\n",
      "### Fine-Tune the System\n",
      "### Present Your Solution\n",
      "### Launch!\n",
      "## B. Autodiff\n",
      "### Manual Differentiation\n",
      "### Finite Difference Approximation\n",
      "### Forward-Mode Autodiff\n",
      "### Reverse-Mode Autodiff\n",
      "## C. Special Data Structures\n",
      "### Strings\n",
      "### Ragged Tensors\n",
      "### Sparse Tensors\n",
      "### Tensor Arrays\n",
      "### Sets\n",
      "### Queues\n",
      "## D. TensorFlow Graphs\n",
      "### TF Functions and Concrete Functions\n",
      "### Exploring Function Definitions and Graphs\n",
      "### A Closer Look at Tracing\n",
      "### Using AutoGraph to Capture Control Flow\n",
      "### Handling Variables and Other Resources in TF Functions\n",
      "### Using TF Functions with Keras (or Not)\n",
      "## Index\n",
      "## About the Author\n"
     ]
    }
   ],
   "source": [
    "print(*result.values(), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
